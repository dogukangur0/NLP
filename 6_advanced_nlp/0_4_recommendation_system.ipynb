{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c15ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039d12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = np.array([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
    "item_ids = np.array([0, 1, 2, 3, 4, 1, 2, 3, 4, 5])\n",
    "ratings  = np.array([5, 4, 3, 2, 1, 4, 5, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f48364",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_train, user_ids_test, item_ids_train, item_ids_test, ratings_train, ratings_test = train_test_split(user_ids, item_ids, ratings, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef16023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_users, num_items, embedding_dim):\n",
    "    user_input = Input(shape = (1,), name = \"user\")\n",
    "    item_input = Input(shape = (1,), name = \"item\")\n",
    "\n",
    "    user_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim, name=\"user_embedding\")(user_input) # shape -> (batch_size, user_input, embedding_dim)\n",
    "    item_embedding = Embedding(input_dim=num_items, output_dim=embedding_dim, name=\"item_embedding\")(item_input) # shape -> (batch_size, user_input, embedding_dim)\n",
    "\n",
    "    user_vecs = Flatten()(user_embedding) # shape -> (batch_size, embedding_dim)\n",
    "    item_vecs = Flatten()(item_embedding) # shape -> (batch_size, embedding_dim)\n",
    "\n",
    "    '''\n",
    "        user_vecs.shape = (1,8) olsun  [[0.1, 0.2, ....]] (batch_size, embedding_dim)\n",
    "        item_vecs.shape = (1,8) olsun  [[0.8, 0.6, ....]] (batch_size, embedding_dim)\n",
    "        axes = 1 -> embedding vektörlerini çarp sonra üm değerleri topla\n",
    "    '''\n",
    "    dot_product = Dot(axes = 1)([user_vecs, item_vecs]) # shape -> (1, 1) -> (batch_size, sum_result)\n",
    "    output = Dense(1)(dot_product)                      # Dense -> fully connected layer (Linear) output = weight * dot_product + bias\n",
    "\n",
    "    model = Model(inputs = [user_input, item_input], outputs = output)\n",
    "    model.compile(optimizer = Adam(learning_rate=0.01), loss = \"mean_squared_error\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61af990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822ms/step - loss: 9.2854 - val_loss: 24.8444\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 9.2049 - val_loss: 24.7583\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 9.1213 - val_loss: 24.6718\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 9.0316 - val_loss: 24.5850\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 8.9334 - val_loss: 24.4980\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8.8246 - val_loss: 24.4107\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8.7037 - val_loss: 24.3230\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8.5699 - val_loss: 24.2349\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 8.4225 - val_loss: 24.1466\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 8.2611 - val_loss: 24.0582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2091b39ccd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = 5\n",
    "num_items = 6\n",
    "embedding_dim = 8\n",
    "model = create_model(num_users, num_items, embedding_dim)\n",
    "model.fit([user_ids_train, item_ids_train], ratings_train, epochs = 10, verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CreateModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embeddding_1 = nn.Embedding(num_embeddings = num_users, embedding_dim = embedding_dim)\n",
    "        self.embeddding_2 = nn.Embedding(num_embeddings = num_items, embedding_dim = embedding_dim)\n",
    "        self.output_layer = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, user_input, item_input):\n",
    "        emb_1 = self.embeddding_1(user_input)\n",
    "        emb_2 = self.embeddding_2(item_input)\n",
    "        dot = torch.sum(emb_1*emb_2, dim = 1, keepdim=True)\n",
    "        return self.output_layer(dot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
