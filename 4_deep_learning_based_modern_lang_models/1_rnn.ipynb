{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6f2e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "17edf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"Yemekler harikaydı, tekrar geleceğim.\",\n",
    "        \"Servis çok yavaştı, memnun kalmadım.\",\n",
    "        \"Garsonlar çok ilgiliydi.\",\n",
    "        \"Yemek soğuk geldi, hiç beğenmedim.\",\n",
    "        \"Tatlılar mükemmeldi, özellikle cheesecake.\",\n",
    "        \"Menü çok sınırlıydı, pek seçenek yoktu.\",\n",
    "        \"Ambiyans çok güzeldi, keyif aldım.\",\n",
    "        \"Masalar çok pisti, hijyen yetersizdi.\",\n",
    "        \"Fiyat performans açısından çok iyiydi.\",\n",
    "        \"Porsiyonlar küçüktü, doymadık.\",\n",
    "        \"Sunum çok şıktı, gözümüz de doydu.\",\n",
    "        \"Yemek çok tuzluydu, yiyemedim.\",\n",
    "        \"Personel çok güler yüzlüydü.\",\n",
    "        \"Garson siparişi karıştırdı, çok bekledik.\",\n",
    "        \"Et tam kıvamındaydı, çok lezzetliydi.\",\n",
    "        \"Salata bayattı, yeşillikler solmuştu.\",\n",
    "        \"Her şey taptazeydi, çok memnun kaldım.\",\n",
    "        \"Çatal bıçaklar temiz değildi.\",\n",
    "        \"Müzik çok güzeldi, ortam huzurluydu.\",\n",
    "        \"Rezervasyon yaptırmamıza rağmen yer yoktu.\",\n",
    "        \"Pizza taş fırında yapılmış gibiydi, çok beğendim.\",\n",
    "        \"Tatlılar çok şekerliydi, yiyemedim.\",\n",
    "        \"Personel çok yardımcıydı.\",\n",
    "        \"Garson çok ilgisizdi.\",\n",
    "        \"Yemekler çok hızlı servis edildi.\",\n",
    "        \"Garsonlar kaba davrandı.\",\n",
    "        \"Fiyatlar makuldü, değerini verdi.\",\n",
    "        \"Tatlılar bayattı.\",\n",
    "        \"Sunum yaratıcıydı, gözümüzü doyurdu.\",\n",
    "        \"Yemekler geç geldi.\",\n",
    "        \"Tavuk iyi pişmişti, harikaydı.\",\n",
    "        \"Mekanda sigara kokuyordu.\",\n",
    "        \"Servis kusursuzdu.\",\n",
    "        \"Sandalyeler rahatsızdı.\",\n",
    "        \"Tatlı olarak profiterol harikaydı.\",\n",
    "        \"Yemek çok yağlıydı.\",\n",
    "        \"Personel çok nazikti.\",\n",
    "        \"Mekan çok kalabalıktı ve gürültülüydü.\",\n",
    "        \"Yemek sonrası çay ikram ettiler, çok hoştu.\",\n",
    "        \"Sipariş eksik geldi.\",\n",
    "        \"Her şey çok lezzetliydi.\",\n",
    "        \"Garson siparişimizi unuttu.\",\n",
    "        \"Ortama bayıldım, dekorasyon çok hoştu.\",\n",
    "        \"Yemeklerin tadı kötüydü.\",\n",
    "        \"Makarnanın sosu enfesti.\",\n",
    "        \"Fiyatlar çok yüksekti.\",\n",
    "        \"Servis elemanı çok kibardı.\",\n",
    "        \"Salonda sinekler vardı.\",\n",
    "        \"Kebap tam kıvamındaydı.\",\n",
    "        \"Lavabolar çok pisti.\",\n",
    "        \"Her şey çok taze ve lezzetliydi.\",\n",
    "        \"Yemekler yanmıştı.\",\n",
    "        \"Tatlılar efsaneydi, parmaklarımızı yedik.\",\n",
    "        \"Masamıza gelen yemek başkasına aitti.\",\n",
    "        \"Tat çok başarılıydı.\",\n",
    "        \"İçecekler sıcaktı.\",\n",
    "        \"Yemek beklediğimizden hızlı geldi.\",\n",
    "        \"Personel ilgisizdi.\",\n",
    "        \"Menüde alerjenler belirtilmişti, takdir ettim.\",\n",
    "        \"Yemekte saç çıktı.\",\n",
    "        \"Şef bizimle ilgilendi, çok nazikti.\",\n",
    "        \"Tatlı geç geldi.\",\n",
    "        \"Kahveleri çok güzeldi.\",\n",
    "        \"Hizmet çok kötüydü.\",\n",
    "        \"Servis çok hızlıydı.\",\n",
    "        \"Tavuk çiğ kalmıştı.\",\n",
    "        \"Çalışanlar çok kibardı.\",\n",
    "        \"Yemek porsiyonu çok azdı.\",\n",
    "        \"Mekandan memnun ayrıldık.\",\n",
    "        \"Tatlılar bayattı.\",\n",
    "        \"Etin tadı çok güzeldi.\",\n",
    "        \"İçerisi havasızdı.\",\n",
    "        \"Çorba tuzluydu.\",\n",
    "        \"Garsonlar çok profesyoneldi.\",\n",
    "        \"Yemekler midemi bozdu.\",\n",
    "        \"Yemekler çok başarılıydı.\",\n",
    "        \"Müzik sesi çok yüksekti.\",\n",
    "        \"Masamız hemen hazırdı.\",\n",
    "        \"Yemek siparişi karıştı.\",\n",
    "        \"Lavabo tertemizdi.\",\n",
    "        \"Masamız geç hazırlandı.\",\n",
    "        \"Tatlılar çok hafifti, beğendim.\",\n",
    "        \"Kahve çok kötüydü.\",\n",
    "        \"Menüdeki her şey harikaydı.\",\n",
    "        \"İçerisi çok sıcaktı, klima çalışmıyordu.\",\n",
    "        \"Kahvaltı tabağı çok doyurucuydu.\",\n",
    "        \"Yemeklerin sunumu kötüydü.\",\n",
    "        \"Garsonlar ilgiliydi.\",\n",
    "        \"Tuzsuzdu, lezzet alamadım.\",\n",
    "        \"Servis oldukça hızlıydı.\",\n",
    "        \"Pide çok sertti.\",\n",
    "        \"Tatlılar muazzamdı.\",\n",
    "        \"Gittiğime pişman oldum.\",\n",
    "        \"Menü çok çeşitliydi.\",\n",
    "        \"Garson hesabı yanlış getirdi.\",\n",
    "        \"Yemekler çok güzeldi.\",\n",
    "        \"Çorba sıcaktı ve çok lezzetliydi.\",\n",
    "    ],\n",
    "    \"label\": [\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\",\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3095159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "032f3908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yemekler harikaydı, tekrar geleceğim.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Servis çok yavaştı, memnun kalmadım.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Garsonlar çok ilgiliydi.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yemek soğuk geldi, hiç beğenmedim.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tatlılar mükemmeldi, özellikle cheesecake.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text     label\n",
       "0       Yemekler harikaydı, tekrar geleceğim.  positive\n",
       "1        Servis çok yavaştı, memnun kalmadım.  negative\n",
       "2                    Garsonlar çok ilgiliydi.  positive\n",
       "3          Yemek soğuk geldi, hiç beğenmedim.  negative\n",
       "4  Tatlılar mükemmeldi, özellikle cheesecake.  positive"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metin temizleme ve preprocessing | tokenization, padding, label encoding, train-test split\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dataset[\"text\"])\n",
    "sequences = tokenizer.texts_to_sequences(dataset[\"text\"])\n",
    "word_index = tokenizer.word_index\n",
    "index_word = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fe5145e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Yemekler harikaydı, tekrar geleceğim.', [3, 8, 49, 50])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequences : dataset içerisindeki text sütununda bulunan tüm cümleleri tarar ve her bir kelimeye birer değer atar.\n",
    "''\n",
    "list(dataset[\"text\"])[0], sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d7932613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri seti içerisindeki tüm cümlelerin kelime uzunlukları hesaplanır ve en yüksek olan değer seçilir.\n",
    "maxlen = max(len(sequence) for sequence in sequences)\n",
    "X = pad_sequences(sequences, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2ffc682e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  3,  8, 49, 50],\n",
       "       [ 0,  0,  5,  1, 51, 16, 52],\n",
       "       [ 0,  0,  0,  0,  9,  1, 21],\n",
       "       [ 0,  0,  2, 53,  6, 54, 55],\n",
       "       [ 0,  0,  0,  4, 56, 57, 58]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a75b128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "y = labelEncoder.fit_transform(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "abfd0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "265f6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sg = 1 : skip-gram modeli -> kelimeden yola çıkarak bağlamı (context) tahmin etmeye çalışır.\n",
    "# sg = 0 : BoW modeli       -> bağlamdan yola çıkarak kelimeyi tahmin etmeye çalışır.\n",
    "# vector size : 50          -> sentence içinde bulunan her kelime için 50 boyutlu vektörler oluşturulur.\n",
    "\n",
    "sentences = [text.split() for text in dataset[\"text\"]]\n",
    "word_2_vec_model = Word2Vec(sentences, vector_size = 50, window = 5, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ee43b3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yemekler', 'harikaydı,', 'tekrar', 'geleceğim.']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "18a7e0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.56351421e-02, -1.90203730e-02, -4.11062239e-04,  6.93839323e-03,\n",
       "       -1.87794445e-03,  1.67635437e-02,  1.80215668e-02,  1.30730132e-02,\n",
       "       -1.42324204e-03,  1.54208085e-02, -1.70686692e-02,  6.41421322e-03,\n",
       "       -9.27599426e-03, -1.01779103e-02,  7.17923651e-03,  1.07406788e-02,\n",
       "        1.55390287e-02, -1.15330126e-02,  1.48667218e-02,  1.32509926e-02,\n",
       "       -7.41960062e-03, -1.74912829e-02,  1.08749345e-02,  1.30195115e-02,\n",
       "       -1.57510047e-03, -1.34197120e-02, -1.41718509e-02, -4.99412045e-03,\n",
       "        1.02865072e-02, -7.33047491e-03, -1.87401194e-02,  7.65347946e-03,\n",
       "        9.76895820e-03, -1.28571270e-02,  2.41711619e-03, -4.14975407e-03,\n",
       "        4.88066689e-05, -1.97670180e-02,  5.38400887e-03, -9.50021297e-03,\n",
       "        2.17529293e-03, -3.15244915e-03,  4.39334614e-03, -1.57631524e-02,\n",
       "       -5.43436781e-03,  5.32639725e-03,  1.06933638e-02, -4.78302967e-03,\n",
       "       -1.90201886e-02,  9.01175756e-03], dtype=float32)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_2_vec_model.wv[\"Yemekler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "52285470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a9fe8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index -> her bir kelimenin id değerlerini tutan dictionary\n",
    "\n",
    "embedding_dim = 50\n",
    "embedding_matrix = np.zeros((len(word_index)+1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in word_2_vec_model.wv:\n",
    "        embedding_matrix[i] = word_2_vec_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c87e99d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4720 - loss: 0.6984 - val_accuracy: 0.5500 - val_loss: 0.6922\n",
      "Epoch 2/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 0.6898 - val_accuracy: 0.5500 - val_loss: 0.6935\n",
      "Epoch 3/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5851 - loss: 0.6897 - val_accuracy: 0.5500 - val_loss: 0.6907\n",
      "Epoch 4/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6417 - loss: 0.6836 - val_accuracy: 0.5500 - val_loss: 0.6971\n",
      "Epoch 5/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5570 - loss: 0.6888 - val_accuracy: 0.5500 - val_loss: 0.6961\n",
      "Epoch 6/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6212 - loss: 0.6765 - val_accuracy: 0.5500 - val_loss: 0.6958\n",
      "Epoch 7/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6173 - loss: 0.6793 - val_accuracy: 0.5500 - val_loss: 0.7094\n",
      "Epoch 8/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.6481 - val_accuracy: 0.5500 - val_loss: 0.7046\n",
      "Epoch 9/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6806 - loss: 0.6598 - val_accuracy: 0.5500 - val_loss: 0.7005\n",
      "Epoch 10/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 0.6522 - val_accuracy: 0.5500 - val_loss: 0.7023\n",
      "Epoch 11/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6162 - loss: 0.6723 - val_accuracy: 0.5500 - val_loss: 0.7143\n",
      "Epoch 12/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6614 - loss: 0.6413 - val_accuracy: 0.5500 - val_loss: 0.7198\n",
      "Epoch 13/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5626 - loss: 0.6911 - val_accuracy: 0.5500 - val_loss: 0.7174\n",
      "Epoch 14/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6661 - loss: 0.6516 - val_accuracy: 0.5500 - val_loss: 0.7252\n",
      "Epoch 15/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6581 - loss: 0.6458 - val_accuracy: 0.5500 - val_loss: 0.7220\n",
      "Epoch 16/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6836 - loss: 0.6513 - val_accuracy: 0.5500 - val_loss: 0.7225\n",
      "Epoch 17/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6020 - loss: 0.6752 - val_accuracy: 0.5500 - val_loss: 0.7338\n",
      "Epoch 18/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5040 - loss: 0.7038 - val_accuracy: 0.5500 - val_loss: 0.7380\n",
      "Epoch 19/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5638 - loss: 0.6814 - val_accuracy: 0.5500 - val_loss: 0.7324\n",
      "Epoch 20/20\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6330 - loss: 0.6527 - val_accuracy: 0.5500 - val_loss: 0.7449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20e07e81cf0>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build train-test and rnn model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = len(word_index)+1, output_dim = embedding_dim, weights = [embedding_matrix], input_length = maxlen, trainable = False))\n",
    "model.add(SimpleRNN(50, return_sequences=False))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 20, batch_size = 3, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "479197fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5500 - loss: 0.7449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7449222803115845, 0.550000011920929)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "af081d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence(sentence):\n",
    "    seq = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_seq = pad_sequences(seq, maxlen)\n",
    "\n",
    "    prediction = model.predict(padded_seq)\n",
    "\n",
    "    prediction_class = (prediction>=0.5)\n",
    "    label = \"positive\" if prediction_class else \"negative\"\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Result: positive\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Result: positive\n"
     ]
    }
   ],
   "source": [
    "result = classify_sentence(\"Restoran çok iyiydi, yemekler harikaydı.\")\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "result = classify_sentence(\"Sunum güzeldi.\")\n",
    "print(f\"Result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
